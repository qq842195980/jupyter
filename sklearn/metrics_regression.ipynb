{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习模型性能衡量指标(回归)以及Python实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 平均绝对误差(Mean Absolute Error, MAE) \n",
    "$$\n",
    "MAE = \\frac{1}{m} \\sum_{i=1}^m |(y_i - \\hat{y_i})|\n",
    "$$\n",
    "其中，$y_i - \\hat{y_i}$ 为测试集上真实值-预测值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE 均方误差(Mean Squared Error, MSE)\n",
    "$$\n",
    "MSE = \\frac{1}{m} \\sum_{i=1}^m (y_i - \\hat{y_i})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE 均方根误差(Mean Squared Error, RMSE)\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{m} \\sum_{i=1}^m (y_i - \\hat{y_i})^2}\n",
    "$$\n",
    "可以看出，$RMSE=sqrt(MSE)$。\n",
    "以上各指标，根据不同业务，会有不同的值大小，不具有可读性，因此还可以使用以下方式进行评测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2(R-Square)\n",
    "$$\n",
    "R_2 = 1 - \\frac{\\sum_{i} (y_i - \\hat{y_i})^2}{\\sum_{i} (y_i - \\overline{y_i})^2}\n",
    "$$\n",
    "\n",
    "其中，分子部分表示真实值与预测值的平方差之和，类似于均方差 MSE；分母部分表示真实值与均值的平方差之和，类似于方差 Var。\n",
    "  \n",
    "根据 R-Squared 的取值，来判断模型的好坏，其取值范围为[0,1]：  \n",
    "- 如果结果是 0，说明模型拟合效果很差；\n",
    "- 如果结果是 1，说明模型无错误。\n",
    "  \n",
    "一般来说，R-Squared 越大，表示模型拟合效果越好。R-Squared 反映的是大概有多准，因为，随着样本数量的增加，R-Square必然增加，无法真正定量说明准确程度，只能大概定量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 校正决定系数(Adjust R-Square)\n",
    "$$\n",
    "R_2\\_{Adjusted}= 1 - \\frac{(1-R^2)(n-1)}{n-p-1}\n",
    "$$\n",
    "\n",
    "其中，n 是样本数量，p 是特征数量。\n",
    "  \n",
    "Adjusted R-Square 抵消样本数量对 R-Square的影响，做到了真正的 0~1，越大越好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "__下面以sklearn中的房价预测为例：__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "max value:50.0\n",
      "min value:5.0\n",
      "ave value:22.532806324110677\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "print(X.shape)\n",
    "# 随机采样25%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33, test_size=0.25)\n",
    "print('max value:{}'.format(np.max(boston.target)))\n",
    "print('min value:{}'.format(np.min(boston.target)))\n",
    "print('ave value:{}'.format(np.mean(boston.target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化数据\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss_X = StandardScaler()\n",
    "ss_y = StandardScaler()\n",
    "\n",
    "X_train = ss_X.fit_transform(X_train)\n",
    "X_test = ss_X.transform(X_test)\n",
    "y_train = ss_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = ss_y.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型训练\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train.ravel())\n",
    "lr_y_predict = lr.predict(X_test)\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgdr = SGDRegressor()\n",
    "sgdr.fit(X_train, y_train.ravel())\n",
    "\n",
    "sgdr_y_predict = sgdr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of LinearRegression:\n",
      "MSE:25.139236520353457\n",
      "RMSE:5.013904319026587\n",
      "MAE:3.5325325437053983\n",
      "r2_score:0.675795501452948\n",
      "r2_adjusted:0.6672291224262983\n",
      "\n",
      "Evaluation of SGDRegressor:\n",
      "MSE:25.833640084254355\n",
      "RMSE:5.08268040351293\n",
      "MAE:3.5131697587650854\n",
      "r2_score:0.6668402271333995\n",
      "r2_adjusted:0.6580372250048105\n"
     ]
    }
   ],
   "source": [
    "# 模型评价\n",
    "from sklearn.metrics import mean_squared_error # MSE\n",
    "from sklearn.metrics import mean_absolute_error # MAE\n",
    "from sklearn.metrics import r2_score # R-Square\n",
    "\n",
    "y_test = ss_y.inverse_transform(y_test)\n",
    "lr_y_predict = ss_y.inverse_transform(lr_y_predict)\n",
    "sgdr_y_predict = ss_y.inverse_transform(sgdr_y_predict)\n",
    "\n",
    "# lr\n",
    "print(\"\\nEvaluation of LinearRegression:\")\n",
    "# MSE：\n",
    "print(\"MSE:{}\".format(mean_squared_error(y_test, lr_y_predict)))\n",
    "# RMSE:\n",
    "print(\"RMSE:{}\".format(np.sqrt(mean_squared_error(y_test, lr_y_predict))))\n",
    "# MAE：\n",
    "print(\"MAE:{}\".format(mean_absolute_error(y_test, lr_y_predict)))\n",
    "# R2：\n",
    "print(\"r2_score:{}\".format(r2_score(y_test, lr_y_predict)))\n",
    "# Adjusted_R2:\n",
    "n = X.shape[0]\n",
    "p = X.shape[1]\n",
    "print(\"r2_adjusted:{}\".format(1-((1-r2_score(y_test, lr_y_predict))*(n-1))/(n-p-1))) \n",
    "      \n",
    "# sgdr\n",
    "print(\"\\nEvaluation of SGDRegressor:\")\n",
    "# MSE：\n",
    "print(\"MSE:{}\".format(mean_squared_error(y_test, sgdr_y_predict)))\n",
    "# RMSE:\n",
    "print(\"RMSE:{}\".format(np.sqrt(mean_squared_error(y_test, sgdr_y_predict))))\n",
    "# MAE：\n",
    "print(\"MAE:{}\".format(mean_absolute_error(y_test, sgdr_y_predict)))\n",
    "# R2：\n",
    "print(\"r2_score:{}\".format(r2_score(y_test, sgdr_y_predict)))\n",
    "# Adjusted_R2:\n",
    "n = X.shape[0]\n",
    "p = X.shape[1]\n",
    "print(\"r2_adjusted:{}\".format(1-((1-r2_score(y_test, sgdr_y_predict))*(n-1))/(n-p-1)))       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
